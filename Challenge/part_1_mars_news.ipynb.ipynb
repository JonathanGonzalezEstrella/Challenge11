{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5d3dba-ba0c-4b96-8b61-b94974df8fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "def init_browser():\n",
    "    # Setup configuration to use ChromeDriverManager to automatically manage the driver\n",
    "    service = Service(executable_path=ChromeDriverManager().install())\n",
    "    return Browser('chrome', service=service, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7719b11-7623-4efe-8779-a2b705f31325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "\n",
    "# Function to initialize the browser using Splinter\n",
    "def init_browser():\n",
    "    # Setup configuration to use ChromeDriverManager to automatically manage the driver\n",
    "    service = Service(executable_path=ChromeDriverManager().install())\n",
    "    return Browser('chrome', service=service, headless=False)\n",
    "\n",
    "# Function to scrape Mars news\n",
    "def scrape_mars_news():\n",
    "    browser = init_browser()\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    browser.visit(url)\n",
    "    \n",
    "    # Allow some time for the page to load\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Create a Beautiful Soup object\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Extract news titles and preview texts\n",
    "    news_list = []\n",
    "    for item in soup.find_all('li', class_='slide'):\n",
    "        try:\n",
    "            title = item.find('div', class_='content_title').get_text().strip()\n",
    "            preview = item.find('div', class_='article_teaser_body').get_text().strip()\n",
    "            news_list.append({'title': title, 'preview': preview})\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    # Close the browser after scraping\n",
    "    browser.quit()\n",
    "    \n",
    "    return news_list\n",
    "\n",
    "# Scrape Mars news and print the results\n",
    "news_data = scrape_mars_news()\n",
    "print(news_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a844b9-0cc5-4963-afa3-85fe97532bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save data to a JSON file\n",
    "with open('mars_news_data.json', 'w') as f:\n",
    "    json.dump(news_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328f0b6b-dc7c-4182-8bf0-69207b0d030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save the scraped data to a JSON file\n",
    "import json\n",
    "\n",
    "with open('mars_news_data.json', 'w') as outfile:\n",
    "    json.dump(news_data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43d8f7-40c6-4136-a93d-6ce3d5e8cdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
